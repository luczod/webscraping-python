{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "textPage = urlopen('http://www.pythonscraping.com/'\n",
    "                   'pages/warandpeace/chapter1.txt')\n",
    "print(textPage.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "textPage = urlopen('http://www.pythonscraping.com/'\n",
    "                   'pages/warandpeace/chapter1-ru.txt')\n",
    "print(str(textPage.read(), 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# <meta charset=\"utf-8\" />\n",
    "html = urlopen('http://en.wikipedia.org/wiki/Python_(programming_language)')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "content = bs.find('div', {'id': 'mw-content-text'}).get_text()\n",
    "content = bytes(content, 'UTF-8')\n",
    "content = content.decode('UTF-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "data = urlopen(\n",
    "    'http://pythonscraping.com/files/MontyPythonAlbums.csv').read().decode(\n",
    "        'ascii', 'ignore')\n",
    "\n",
    "# encapsulate the string with a StringIO object so that it behaves like a file.\n",
    "dataFile = StringIO(data)\n",
    "csvReader = csv.reader(dataFile)\n",
    "\"\"\" \n",
    "for row in csvReader:\n",
    "    print(row) \"\"\"\n",
    "\n",
    "for row in csvReader:\n",
    "    print('The album \"' + row[0] + '\" was released in ' + str(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "data = urlopen(\n",
    "    'http://pythonscraping.com/files/MontyPythonAlbums.csv').read().decode(\n",
    "        'ascii', 'ignore')\n",
    "\n",
    "# encapsulate the string with a StringIO object so that it behaves like a file.\n",
    "dataFile = StringIO(data)\n",
    "dictReader = csv.DictReader(dataFile)\n",
    "print(dictReader.fieldnames)\n",
    "\n",
    "for row in dictReader:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from pdfminer.pdfinterp import PDFResourceManager, process_pdf\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from io import StringIO\n",
    "from io import open\n",
    "\n",
    "\n",
    "def readPDF(pdfFile):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    process_pdf(rsrcmgr, device, pdfFile)\n",
    "    device.close()\n",
    "    content = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return content\n",
    "\n",
    "\n",
    "pdfFile = urlopen('http://pythonscraping.com/pages/warandpeace/chapter1.pdf')\n",
    "# pdfFile = open('../pages/warandpeace/chapter1.pdf', 'rb') using local file\n",
    "outputString = readPDF(pdfFile)\n",
    "print(outputString)\n",
    "pdfFile.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "wordFile = urlopen('http://pythonscraping.com/pages/AWordDocument.docx').read()\n",
    "# BytesIO is analogous to StringIO\n",
    "wordFile = BytesIO(wordFile)\n",
    "document = ZipFile(wordFile)\n",
    "xml_content = document.read('word/document.xml')\n",
    "print(xml_content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "wordFile = urlopen('http://pythonscraping.com/pages/AWordDocument.docx').read()\n",
    "wordFile = BytesIO(wordFile)\n",
    "document = ZipFile(wordFile)\n",
    "xml_content = document.read('word/document.xml')\n",
    "\n",
    "wordObj = BeautifulSoup(xml_content.decode('utf-8'), 'xml')\n",
    "textStrings = wordObj.find_all('w:t')\n",
    "\n",
    "for textElem in textStrings:\n",
    "    print(textElem.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
